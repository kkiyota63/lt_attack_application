import streamlit as st
import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score
from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode
import shap
import matplotlib.pyplot as plt
from st_aggrid import GridUpdateMode
from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, recall_score, precision_score, confusion_matrix


# ãƒãƒƒãƒ”ãƒ³ã‚°æƒ…å ±ã®èª­ã¿è¾¼ã¿
@st.cache_data
def load_mapping():
    return pd.read_csv("mapping.csv")

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ç”¨ã®é–¢æ•°
def clear_mapping_cache():
    load_mapping.clear()


# ã‚¿ã‚¤ãƒˆãƒ«
st.title("ä¸æ­£å£åº§æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ")

# å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
@st.cache_resource
def load_model():
    model = xgb.XGBClassifier()
    model.load_model("../models/balanced_fraud_model.model")
    return model

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¦æœ€æ–°ã®mapping.csvã‚’èª­ã¿è¾¼ã¿
clear_mapping_cache()
model = load_model()
mapping_df = load_mapping()

# ã‚«ãƒ©ãƒ åã‚’æ—¥æœ¬èªã«å¤‰æ›ã™ã‚‹é–¢æ•°
def rename_columns(df):
    mapping_dict = dict(zip(mapping_df['feature_name'], mapping_df['description']))
    return df.rename(columns=mapping_dict)

# SHAPå€¤ã‚’ç†ç”±ã‚³ãƒ¼ãƒ‰ã«å¤‰æ›ã™ã‚‹é–¢æ•°
def get_reason_codes(shap_values, feature_names, top_n=5, min_contribution=0.1):
    # æ­£ã®å¯„ä¸ã®ã¿ã‚’å–å¾—
    positive_shap = shap_values[shap_values > 0]
    positive_features = [feature_names[i] for i in range(len(shap_values)) if shap_values[i] > 0]
    
    if len(positive_shap) == 0:
        return ["ãƒªã‚¹ã‚¯è¦å› ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"]
    
    # å¯„ä¸åº¦ã§ã‚½ãƒ¼ãƒˆ
    sorted_indices = np.argsort(positive_shap)[::-1]
    total_contribution = np.sum(positive_shap)
    
    reason_codes = []
    cumulative_contribution = 0
    
    # ç†ç”±ã‚³ãƒ¼ãƒ‰ã®ãƒãƒƒãƒ”ãƒ³ã‚°è¾æ›¸ã‚’ä½œæˆ
    reason_mapping = dict(zip(mapping_df['feature_name'], mapping_df['reason_code']))
    
    for i, idx in enumerate(sorted_indices[:top_n]):
        contribution = positive_shap[idx]
        contribution_ratio = contribution / total_contribution
        
        if contribution_ratio >= min_contribution:
            feature_name = positive_features[idx]
            reason_code = reason_mapping.get(feature_name, feature_name)
            # SHAPå€¤ã‚’ãã®ã¾ã¾è¡¨ç¤ºï¼ˆå¿…è¦ãªã‚‰å°æ•°ç‚¹ä»¥ä¸‹èª¿æ•´ï¼‰
            reason_codes.append(f"{reason_code} (AIã®åˆ¤æ–­æ ¹æ‹ ã‚¹ã‚³ã‚¢: {contribution:.2f}ãƒã‚¤ãƒ³ãƒˆ)")
            cumulative_contribution += contribution_ratio
    
    # æ®‹ã‚Šã®å¯„ä¸åº¦ãŒ10%ä»¥ä¸Šã‚ã‚‹å ´åˆã¯ã€Œãã®ä»–ã€ã¨ã—ã¦è¿½åŠ 
    remaining = 1 - cumulative_contribution
    if remaining >= min_contribution:
        reason_codes.append("ãã®ä»–")
    
    return reason_codes if reason_codes else ["ãƒªã‚¹ã‚¯è¦å› ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"]


# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ãƒ•ã‚¡ã‚¤ãƒ«å…¥åŠ›ã‚’é…ç½®
st.sidebar.header("å£åº§ç”³è«‹æƒ…å ±ã‚’å…¥åŠ›")
uploaded_file = st.sidebar.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["csv"])

@st.cache_resource
def get_explainer_and_shap_values(_model, X):
    explainer = shap.TreeExplainer(_model)
    shap_values = explainer.shap_values(X)
    return explainer, shap_values



def evaluate(predictions, y_true, threshold):
    # ROCæ›²ç·šæç”»ï¼ˆplot_rocé–¢æ•°ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼å®šç¾©ã¨ä»®å®šï¼‰
    fprs, tprs, _ = roc_curve(y_true, predictions)

    # ROC-AUCã‚¹ã‚³ã‚¢è¨ˆç®—
    auc = roc_auc_score(y_true, predictions)

    # é–¾å€¤ã«ã‚ˆã‚‹ãƒ©ãƒ™ãƒ«äºˆæ¸¬
    pred_labels = (predictions >= threshold).astype(int)

    # å„ç¨®è©•ä¾¡æŒ‡æ¨™è¨ˆç®—
    acc = accuracy_score(y_true, pred_labels)
    rec = recall_score(y_true, pred_labels)
    prec = precision_score(y_true, pred_labels)

    tn, fp, fn, tp = confusion_matrix(y_true, pred_labels).ravel()
    fpr = fp / (fp + tn)

    total = len(pred_labels)
    predicted_frauds = pred_labels.sum()
    predicted_fraud_rate = predicted_frauds / total * 100

    # æ‹…å½“è€…ãŒãƒã‚§ãƒƒã‚¯ã™ã‚‹å£åº§æ•°ã®å‰Šæ¸›ç‡è¨ˆç®—ï¼ˆãƒ¢ãƒ‡ãƒ«é©ç”¨å‰ã¯å…¨æ•°ãƒã‚§ãƒƒã‚¯æƒ³å®šï¼‰
    pre_model_check_count = total
    post_model_check_count = predicted_frauds
    reduction_rate = 1 - (post_model_check_count / pre_model_check_count)

    # ãƒ¢ãƒ‡ãƒ«é©ç”¨å‰å¾Œã®1ã®å‰²åˆ
    pre_ratio = y_true.mean()
    if post_model_check_count > 0:
        post_ratio = y_true[pred_labels == 1].mean()
    else:
        post_ratio = 0

    # çµæœå‡ºåŠ›ï¼ˆprintã¨streamlitä¸¡æ–¹ï¼‰
    print(f"AUCï¼ˆROCæ›²ç·šã®ä¸‹ã®é¢ç©ï¼‰: {auc:.4f}")
    st.write(f"AUCï¼ˆROCæ›²ç·šã®ä¸‹ã®é¢ç©ï¼‰: {auc:.4f}")

    print(f"å†ç¾ç‡ï¼ˆfraud=1 ã®ã†ã¡æ­£ã—ãæ¤œå‡ºã—ãŸå‰²åˆï¼‰: {rec:.4f}")
    st.write(f"å†ç¾ç‡ï¼ˆfraud=1 ã®ã†ã¡æ­£ã—ãæ¤œå‡ºã—ãŸå‰²åˆï¼‰: {rec:.4f}")

    print(f"é©åˆç‡ï¼ˆfraud=1 ã¨äºˆæ¸¬ã—ãŸã†ã¡æ­£è§£ã—ãŸå‰²åˆï¼‰: {prec:.4f}")
    st.write(f"é©åˆç‡ï¼ˆfraud=1 ã¨äºˆæ¸¬ã—ãŸã†ã¡æ­£è§£ã—ãŸå‰²åˆï¼‰: {prec:.4f}")

    print(f"å½é™½æ€§ç‡ï¼ˆfraud=0 ã‚’èª¤ã£ã¦1ã¨äºˆæ¸¬ã—ãŸå‰²åˆï¼‰: {fpr:.4f}")
    st.write(f"å½é™½æ€§ç‡ï¼ˆfraud=0 ã‚’èª¤ã£ã¦1ã¨äºˆæ¸¬ã—ãŸå‰²åˆï¼‰: {fpr:.4f}")

    print(f"ã—ãã„å€¤ï¼ˆthresholdï¼‰: {threshold}")
    st.write(f"ã—ãã„å€¤ï¼ˆthresholdï¼‰: {threshold}")

    print(f"æ­£è§£ç‡ï¼ˆAccuracyï¼‰: {acc:.4f}")
    st.write(f"æ­£è§£ç‡ï¼ˆAccuracyï¼‰: {acc:.4f}")

    print(f"fraudã¨äºˆæ¸¬ã—ãŸä»¶æ•°: {predicted_frauds} ä»¶ / å…¨ä½“ {total} ä»¶ "
          f"ï¼ˆ{predicted_fraud_rate:.2f}%ï¼‰")
    st.write(f"fraudã¨äºˆæ¸¬ã—ãŸä»¶æ•°: {predicted_frauds} ä»¶ / å…¨ä½“ {total} ä»¶ "
          f"ï¼ˆ{predicted_fraud_rate:.2f}%ï¼‰")

    print(f"æ‹…å½“è€…ãŒãƒã‚§ãƒƒã‚¯ã™ã‚‹å£åº§æ•°ã®å‰Šæ¸›ç‡: {reduction_rate:.4f}")
    st.write(f"æ‹…å½“è€…ãŒãƒã‚§ãƒƒã‚¯ã™ã‚‹å£åº§æ•°ã®å‰Šæ¸›ç‡: {reduction_rate:.4f}")

    print(f"ãƒ¢ãƒ‡ãƒ«é©ç”¨å‰ã®1ã®å‰²åˆ: {pre_ratio:.4f}")
    st.write(f"ãƒ¢ãƒ‡ãƒ«é©ç”¨å‰ã®1ã®å‰²åˆ: {pre_ratio:.4f}")

    print(f"ãƒ¢ãƒ‡ãƒ«é©ç”¨å¾Œã®1ã®å‰²åˆï¼ˆäºˆæ¸¬ãŒ1ã®ã‚°ãƒ«ãƒ¼ãƒ—å†…ï¼‰: {post_ratio:.4f}")
    st.write(f"ãƒ¢ãƒ‡ãƒ«é©ç”¨å¾Œã®1ã®å‰²åˆï¼ˆäºˆæ¸¬ãŒ1ã®ã‚°ãƒ«ãƒ¼ãƒ—å†…ï¼‰: {post_ratio:.4f}")


if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    
    # æ¨è«–å¯¾è±¡ã‚’ month >= 6 ã«çµã‚‹
    df_inference = df[df["month"] >= 6].copy()
    X_test = df_inference.drop(['fraud_bool'], axis=1)
    y_test = df_inference['fraud_bool']

    predictions = model.predict_proba(X_test)[:, 1]

    result_df = X_test.copy()

    threshold = 0.92
    
    result_df["äºˆæ¸¬ç¢ºç‡"] = predictions
    result_df["äºˆæ¸¬ãƒ©ãƒ™ãƒ«"] = (predictions >= threshold).astype(int)
    result_df["æ­£è§£ãƒ©ãƒ™ãƒ«"] = y_test.values

    #evaluate(predictions, y_test, threshold)
    
    # ã‚«ãƒ©ãƒ åã‚’æ—¥æœ¬èªã«å¤‰æ›
    result_df = rename_columns(result_df)

    st.subheader("å‡çµå¯¾è±¡å€™è£œãƒªã‚¹ãƒˆ")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«è¡¨ç¤ºä»¶æ•°é¸æŠã‚’é…ç½®
    max_rows = st.sidebar.selectbox(
        "è¡¨ç¤ºã™ã‚‹ä»¶æ•°ã‚’é¸æŠ",
        options=[100, 200, 500, 1000, 5000, 100000],
        index=3
    )
    filtered_df = result_df[result_df["äºˆæ¸¬ãƒ©ãƒ™ãƒ«"] == 1]

    # SHAPå€¤ã‚’è¨ˆç®—ã—ã¦ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚°ç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
    explainer, shap_values = get_explainer_and_shap_values(model, X_test)
    shap_val_pos = shap_values[1] if isinstance(shap_values, list) else shap_values
    
    # ãƒ•ã‚£ãƒ«ã‚¿ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®SHAPå€¤ã‚’å–å¾—
    filtered_indices = filtered_df.index.tolist()
    filtered_shap_indices = [X_test.index.get_loc(idx) for idx in filtered_indices]
    filtered_shap_values = shap_val_pos[filtered_shap_indices]
    
    # SHAPå€¤ã«åŸºã¥ãè‰²åˆ†ã‘é–¢æ•°
    def style_dataframe_by_shap(df, shap_values):
        def apply_shap_colors(row):
            colors = []
            feature_columns = [col for col in df.columns if col not in ['äºˆæ¸¬ç¢ºç‡', 'äºˆæ¸¬ãƒ©ãƒ™ãƒ«', 'æ­£è§£ãƒ©ãƒ™ãƒ«']]
            
            for col in df.columns:
                if col in feature_columns:
                    col_idx = feature_columns.index(col)
                    row_idx = row.name
                    
                    if row_idx < len(shap_values) and col_idx < shap_values.shape[1]:
                        shap_val = shap_values[row_idx, col_idx]
                        
                        # æ­£è¦åŒ–ï¼ˆå…¨ä½“ã®æœ€å¤§çµ¶å¯¾å€¤ã§å‰²ã‚‹ï¼‰
                        max_abs = np.abs(shap_values).max()
                        if max_abs > 0:
                            normalized_shap = shap_val / max_abs
                        else:
                            normalized_shap = 0
                        
                        # è‰²ã®å¼·åº¦ã‚’è¨ˆç®—
                        intensity = min(abs(normalized_shap), 1) * 0.6
                        
                        if shap_val > 0:
                            # èµ¤ç³»ï¼ˆãƒªã‚¹ã‚¯ä¸Šæ˜‡ï¼‰
                            colors.append(f'background-color: rgba(255, 100, 100, {intensity})')
                        elif shap_val < 0:
                            # é’ç³»ï¼ˆãƒªã‚¹ã‚¯ä¸‹é™ï¼‰
                            colors.append(f'background-color: rgba(100, 150, 255, {intensity})')
                        else:
                            colors.append('')
                    else:
                        colors.append('')
                else:
                    colors.append('')
            
            return colors
        
        return df.style.apply(apply_shap_colors, axis=1)
    
    # è¡¨ç¤ºç”¨ãƒ‡ãƒ¼ã‚¿ã¨SHAPå€¤
    display_df = filtered_df.head(max_rows).reset_index(drop=True)
    display_shap = filtered_shap_values[:len(display_df)]
    
    # ã‚»ãƒ«ã‚¯ãƒªãƒƒã‚¯æ©Ÿèƒ½ä»˜ãã®è¡¨ã‚’å®Ÿè£…
    if len(display_shap) > 0:
        # å‡¡ä¾‹ã‚’è¡¨ç¤º
        st.markdown("ğŸ”´ èµ¤ç³» = ãƒªã‚¹ã‚¯ä¸Šæ˜‡è¦å›   |  ğŸ”µ é’ç³» = ãƒªã‚¹ã‚¯ä¸‹é™è¦å› ")
        
        # è‰²åˆ†ã‘ã•ã‚ŒãŸè¡¨ã‚’è¡¨ç¤ºï¼ˆã‚¯ãƒªãƒƒã‚¯é¸æŠæ©Ÿèƒ½ä»˜ãï¼‰
        styled_df = style_dataframe_by_shap(display_df, display_shap)
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã§ã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸè¡Œã‚’ç®¡ç†
        if 'clicked_row' not in st.session_state:
            st.session_state.clicked_row = None
    
        
        # é¸æŠç”¨ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹åˆ—ã‚’è¿½åŠ 
        display_df_with_select = display_df.copy()
        display_df_with_select.insert(0, 'é¸æŠ', False)
        
        # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«è¡Œé¸æŠã‚’é…ç½®
        st.sidebar.header("AIã®åˆ¤æ–­æ ¹æ‹ ã‚’è¡¨ç¤º")
        
        # ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã§è¡Œé¸æŠï¼ˆäºˆæ¸¬ç¢ºç‡ã‚‚è¡¨ç¤ºï¼‰
        row_options = []
        for i in range(len(display_df)):
            prob = display_df.iloc[i]['äºˆæ¸¬ç¢ºç‡']
            row_options.append(f"å£åº§ç•ªå· {i+1} ")
        
        selected_option = st.sidebar.selectbox(
            "å£åº§ã‚’é¸æŠã—ã¦ãã ã•ã„",
            options=row_options,
            index=0,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯1è¡Œç›®
            key="row_selector"
        )
        # é¸æŠã•ã‚ŒãŸè¡Œç•ªå·ã‚’æŠ½å‡º
        selected_row_number = row_options.index(selected_option)
        
        # é¸æŠã•ã‚ŒãŸè¡Œã®æƒ…å ±ã‚’ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«è¡¨ç¤º
        if 0 <= selected_row_number < len(display_df):
            prob = display_df.iloc[selected_row_number]['äºˆæ¸¬ç¢ºç‡']
            pred_label = display_df.iloc[selected_row_number]['äºˆæ¸¬ãƒ©ãƒ™ãƒ«']
            true_label = display_df.iloc[selected_row_number]['æ­£è§£ãƒ©ãƒ™ãƒ«']
            selected_rows_data = True
        else:
            selected_rows_data = False
        
        styled_df = style_dataframe_by_shap(display_df, display_shap)
        st.dataframe(styled_df, use_container_width=True)
        
        # é¸æŠã•ã‚ŒãŸè¡Œã®å‡¦ç†
        if selected_rows_data and 0 <= selected_row_number < len(filtered_df):
            original_index = filtered_df.index[selected_row_number]
            sample_index = X_test.index.get_loc(original_index)
    else:
        st.dataframe(display_df, use_container_width=True)
        selected_rows_data = False
    
    # sample_indexã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼ˆé¸æŠã•ã‚Œã¦ã„ãªã„å ´åˆï¼‰
    if 'sample_index' not in locals():
        sample_index = 0
    
    if selected_rows_data:
        
        # SHAPå€¤ã‚’è¨ˆç®—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã¦ã„ã‚‹ã‚‚ã®ã‚’ä½¿ç”¨ï¼‰
        explainer, shap_values = get_explainer_and_shap_values(model, X_test)
        shap_val_pos = shap_values[1] if isinstance(shap_values, list) else shap_values
        base_value = explainer.expected_value[1] if isinstance(explainer.expected_value, list) else explainer.expected_value
        
        # ç†ç”±ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¦è¡¨ç¤º
        reason_codes = get_reason_codes(shap_val_pos[sample_index], X_test.columns.tolist())
        st.subheader("AIã®åˆ¤æ–­æ ¹æ‹ ")
        for i, reason in enumerate(reason_codes, 1):
            st.write(f"{i}. {reason}")
        
        # ã‚¦ã‚©ãƒ¼ã‚¿ãƒ¼ãƒ•ã‚©ãƒ¼ãƒ«å›³ã‚’ä½œæˆ
        fig, ax = plt.subplots(figsize=(12, 8))
        
        shap.plots.waterfall(
            shap.Explanation(
                values=shap_val_pos[sample_index],
                base_values=base_value,
                data=X_test.iloc[sample_index],
                feature_names=X_test.columns
            ),
            show=False
        )
        
        #st.pyplot(fig)
        #plt.close(fig)  # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã‚’é˜²ã
        
    else:
        st.info("è©³ç´°åˆ†æã‚’è¡¨ç¤ºã™ã‚‹ã«ã¯ã€ä¸Šã®ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã‹ã‚‰è¡Œã‚’é¸æŠã—ã¦ãã ã•ã„")
